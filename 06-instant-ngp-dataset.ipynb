{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06-instant-ngp-dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Instant NGP Dataset\n",
        "\n",
        "\n",
        "made by [Atem Konevskikh](https://aiculedssul.net/)\n",
        "\n",
        "based on [official instant-ngp repsitory](https://github.com/NVlabs/instant-ngp)"
      ],
      "metadata": {
        "id": "-fWq3BQC20Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install\n",
        "%env QT_QPA_PLATFORM=offscreen\n",
        "!apt-get install colmap ffmpeg"
      ],
      "metadata": {
        "id": "9WGSLZPZ2zca",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Libraries\n",
        "import argparse\n",
        "import os\n",
        "from pathlib import Path, PurePosixPath\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import sys\n",
        "import math\n",
        "import cv2\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W3pogULtGYUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "a7UUMdfN2wOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5aa91f2-c78f-4dbc-f022-bf8dcf29684e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set directory\n",
        "#@markdown Results folder\n",
        "result_dir = '/content/drive/MyDrive/workshops/sciarc/nerf/test2' # @param {type:'string'}\n",
        "images = f\"{result_dir}/images\"\n",
        "text = f\"{result_dir}/colmap_text\"\n",
        "sparse = f\"{result_dir}/colmap_sparse\"\n",
        "db = f\"{result_dir}/colmap.db\"\n",
        "out_path = f\"{result_dir}/transforms.json\"\n",
        "\n",
        "!mkdir -p $result_dir\n",
        "!mkdir $images $text $sparse\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dXkGiA-E_u5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process Video\n",
        "#@markdown Video file\n",
        "video = '/content/drive/MyDrive/workshops/sciarc/IMG_0680.MOV' # @param {type:'string'}\n",
        "#@markdown Extract frames per second\n",
        "fps =  2# @param {type:'integer'}\n",
        "\n",
        "\n",
        "!ffmpeg -i {video} -qscale:v 1 -qmin 1 -vf \"fps={fps}\" {images}/%04d.jpg"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tWmodvXt8dv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process Images\n",
        "#@markdown Image folder\n",
        "img_folder = '' # @param {type:'string'}\n",
        "\n",
        "!cp {img_folder}/*  {images}/."
      ],
      "metadata": {
        "cellView": "form",
        "id": "13xKGX2ADD4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Colmap Feature Extraction\n",
        "!colmap feature_extractor \\\n",
        "        --SiftExtraction.use_gpu 0 \\\n",
        "        --SiftExtraction.estimate_affine_shape=true \\\n",
        "        --SiftExtraction.domain_size_pooling=true \\\n",
        "        --ImageReader.camera_model OPENCV \\\n",
        "        --ImageReader.single_camera 1 \\\n",
        "        --database_path {db} \\\n",
        "        --image_path {images}\n"
      ],
      "metadata": {
        "id": "NW3Jyc10-Nlh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Colmap Feature Matching\n",
        "#@markdown Select which matcher colmap should use. Sequential for videos, exhaustive for adhoc images\n",
        "colmap_matcher = 'sequential' # @param [\"exhaustive\",\"sequential\",\"spatial\",\"transitive\",\"vocab_tree\"]\n",
        "\n",
        "!colmap {colmap_matcher}_matcher \\\n",
        "        --SiftMatching.use_gpu 0 \\\n",
        "        --SiftMatching.guided_matching=true \\\n",
        "        --database_path {db}"
      ],
      "metadata": {
        "id": "VyUPIUheCFi0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run Colmap Reconstruction\n",
        "# @markdown Run structure-from-motion to compute camera parameters\n",
        "\n",
        "!colmap mapper \\\n",
        "        --database_path {db} \\\n",
        "        --image_path {images} \\\n",
        "        --export_path {sparse}\n",
        "\n",
        "!colmap bundle_adjuster \\\n",
        "       --input_path {sparse}/0 \\\n",
        "       --output_path {sparse}/0 \\\n",
        "       --BundleAdjustment.refine_principal_point 1\n",
        "\n",
        "!colmap model_converter \\\n",
        "        --input_path {sparse}/0 \\\n",
        "        --output_path {text} \\\n",
        "        --output_type TXT"
      ],
      "metadata": {
        "id": "fhvRT5UXDyFg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Transform file\n",
        "#@markdown Large scene scale factor. 1 = scene fits in unit cube; power of 2 up to 16\n",
        "AABB_SCALE = \"8\" # @param [1,2,4,8,16]\n",
        "#@markdown Skip this many images from the start\n",
        "SKIP_EARLY = 0 # @param {type:'integer'}\n",
        "IMAGE_FOLDER = images\n",
        "TEXT_FOLDER = text\n",
        "OUT_PATH = out_path\n",
        "\n",
        "AABB_SCALE = int(AABB_SCALE)\n",
        "#@markdown keep transforms.json in COLMAP's original frame of reference (this will avoid reorienting and repositioning the scene for preview and rendering)\n",
        "keep_colmap_coords = False # @param {type:'boolean'}\n",
        "\n",
        "\n",
        "def variance_of_laplacian(image):\n",
        "\treturn cv2.Laplacian(image, cv2.CV_64F).var()\n",
        "\n",
        "def sharpness(imagePath):\n",
        "\timage = cv2.imread(imagePath)\n",
        "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\tfm = variance_of_laplacian(gray)\n",
        "\treturn fm\n",
        "\n",
        "def qvec2rotmat(qvec):\n",
        "\treturn np.array([\n",
        "\t\t[\n",
        "\t\t\t1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
        "\t\t\t2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
        "\t\t\t2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]\n",
        "\t\t], [\n",
        "\t\t\t2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
        "\t\t\t1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
        "\t\t\t2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]\n",
        "\t\t], [\n",
        "\t\t\t2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
        "\t\t\t2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
        "\t\t\t1 - 2 * qvec[1]**2 - 2 * qvec[2]**2\n",
        "\t\t]\n",
        "\t])\n",
        "\n",
        "def rotmat(a, b):\n",
        "\ta, b = a / np.linalg.norm(a), b / np.linalg.norm(b)\n",
        "\tv = np.cross(a, b)\n",
        "\tc = np.dot(a, b)\n",
        "\ts = np.linalg.norm(v)\n",
        "\tkmat = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
        "\treturn np.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s ** 2 + 1e-10))\n",
        "\n",
        "def closest_point_2_lines(oa, da, ob, db): # returns point closest to both rays of form o+t*d, and a weight factor that goes to 0 if the lines are parallel\n",
        "\tda = da / np.linalg.norm(da)\n",
        "\tdb = db / np.linalg.norm(db)\n",
        "\tc = np.cross(da, db)\n",
        "\tdenom = np.linalg.norm(c)**2\n",
        "\tt = ob - oa\n",
        "\tta = np.linalg.det([t, db, c]) / (denom + 1e-10)\n",
        "\ttb = np.linalg.det([t, da, c]) / (denom + 1e-10)\n",
        "\tif ta > 0:\n",
        "\t\tta = 0\n",
        "\tif tb > 0:\n",
        "\t\ttb = 0\n",
        "\treturn (oa+ta*da+ob+tb*db) * 0.5, denom\n",
        "  \n",
        "print(f\"outputting to {OUT_PATH}...\")\n",
        "with open(os.path.join(TEXT_FOLDER,\"cameras.txt\"), \"r\") as f:\n",
        "  angle_x = math.pi / 2\n",
        "  for line in f:\n",
        "    # 1 SIMPLE_RADIAL 2048 1536 1580.46 1024 768 0.0045691\n",
        "    # 1 OPENCV 3840 2160 3178.27 3182.09 1920 1080 0.159668 -0.231286 -0.00123982 0.00272224\n",
        "    # 1 RADIAL 1920 1080 1665.1 960 540 0.0672856 -0.0761443\n",
        "    if line[0] == \"#\":\n",
        "      continue\n",
        "    els = line.split(\" \")\n",
        "    w = float(els[2])\n",
        "    h = float(els[3])\n",
        "    fl_x = float(els[4])\n",
        "    fl_y = float(els[4])\n",
        "    k1 = 0\n",
        "    k2 = 0\n",
        "    p1 = 0\n",
        "    p2 = 0\n",
        "    cx = w / 2\n",
        "    cy = h / 2\n",
        "    if els[1] == \"SIMPLE_PINHOLE\":\n",
        "      cx = float(els[5])\n",
        "      cy = float(els[6])\n",
        "    elif els[1] == \"PINHOLE\":\n",
        "      fl_y = float(els[5])\n",
        "      cx = float(els[6])\n",
        "      cy = float(els[7])\n",
        "    elif els[1] == \"SIMPLE_RADIAL\":\n",
        "      cx = float(els[5])\n",
        "      cy = float(els[6])\n",
        "      k1 = float(els[7])\n",
        "    elif els[1] == \"RADIAL\":\n",
        "      cx = float(els[5])\n",
        "      cy = float(els[6])\n",
        "      k1 = float(els[7])\n",
        "      k2 = float(els[8])\n",
        "    elif els[1] == \"OPENCV\":\n",
        "      fl_y = float(els[5])\n",
        "      cx = float(els[6])\n",
        "      cy = float(els[7])\n",
        "      k1 = float(els[8])\n",
        "      k2 = float(els[9])\n",
        "      p1 = float(els[10])\n",
        "      p2 = float(els[11])\n",
        "    else:\n",
        "      print(\"unknown camera model \", els[1])\n",
        "    # fl = 0.5 * w / tan(0.5 * angle_x);\n",
        "    angle_x = math.atan(w / (fl_x * 2)) * 2\n",
        "    angle_y = math.atan(h / (fl_y * 2)) * 2\n",
        "    fovx = angle_x * 180 / math.pi\n",
        "    fovy = angle_y * 180 / math.pi\n",
        "\n",
        "print(f\"camera:\\n\\tres={w,h}\\n\\tcenter={cx,cy}\\n\\tfocal={fl_x,fl_y}\\n\\tfov={fovx,fovy}\\n\\tk={k1,k2} p={p1,p2} \")\n",
        "\n",
        "with open(os.path.join(TEXT_FOLDER,\"images.txt\"), \"r\") as f:\n",
        "  i = 0\n",
        "  bottom = np.array([0.0, 0.0, 0.0, 1.0]).reshape([1, 4])\n",
        "  out = {\n",
        "    \"camera_angle_x\": angle_x,\n",
        "    \"camera_angle_y\": angle_y,\n",
        "    \"fl_x\": fl_x,\n",
        "    \"fl_y\": fl_y,\n",
        "    \"k1\": k1,\n",
        "    \"k2\": k2,\n",
        "    \"p1\": p1,\n",
        "    \"p2\": p2,\n",
        "    \"cx\": cx,\n",
        "    \"cy\": cy,\n",
        "    \"w\": w,\n",
        "    \"h\": h,\n",
        "    \"aabb_scale\": AABB_SCALE,\n",
        "    \"frames\": [],\n",
        "  }\n",
        "\n",
        "  up = np.zeros(3)\n",
        "  for line in f:\n",
        "    line = line.strip()\n",
        "    if line[0] == \"#\":\n",
        "      continue\n",
        "    i = i + 1\n",
        "    if i < SKIP_EARLY*2:\n",
        "      continue\n",
        "    if  i % 2 == 1:\n",
        "      elems=line.split(\" \") # 1-4 is quat, 5-7 is trans, 9ff is filename (9, if filename contains no spaces)\n",
        "      #name = str(PurePosixPath(Path(IMAGE_FOLDER, elems[9])))\n",
        "      # why is this requireing a relitive path while using ^\n",
        "      image_rel = os.path.relpath(IMAGE_FOLDER)\n",
        "      name = str(f\"./{image_rel}/{'_'.join(elems[9:])}\")\n",
        "      fname = str(f\"images/{'_'.join(elems[9:])}\")\n",
        "      b=sharpness(name)\n",
        "      print(name, \"sharpness=\",b)\n",
        "      image_id = int(elems[0])\n",
        "      qvec = np.array(tuple(map(float, elems[1:5])))\n",
        "      tvec = np.array(tuple(map(float, elems[5:8])))\n",
        "      R = qvec2rotmat(-qvec)\n",
        "      t = tvec.reshape([3,1])\n",
        "      m = np.concatenate([np.concatenate([R, t], 1), bottom], 0)\n",
        "      c2w = np.linalg.inv(m)\n",
        "      if not keep_colmap_coords:\n",
        "        c2w[0:3,2] *= -1 # flip the y and z axis\n",
        "        c2w[0:3,1] *= -1\n",
        "        c2w = c2w[[1,0,2,3],:] # swap y and z\n",
        "        c2w[2,:] *= -1 # flip whole world upside down\n",
        "\n",
        "        up += c2w[0:3,1]\n",
        "\n",
        "      frame={\"file_path\": fname,\"sharpness\":b,\"transform_matrix\": c2w}\n",
        "      out[\"frames\"].append(frame)\n",
        "nframes = len(out[\"frames\"])\n",
        "\n",
        "if keep_colmap_coords:\n",
        "  flip_mat = np.array([\n",
        "    [1, 0, 0, 0],\n",
        "    [0, -1, 0, 0],\n",
        "    [0, 0, -1, 0],\n",
        "    [0, 0, 0, 1]\n",
        "  ])\n",
        "\n",
        "  for f in out[\"frames\"]:\n",
        "    f[\"transform_matrix\"] = np.matmul(f[\"transform_matrix\"], flip_mat) # flip cameras (it just works)\n",
        "else:\n",
        "  # don't keep colmap coords - reorient the scene to be easier to work with\n",
        "  \n",
        "  up = up / np.linalg.norm(up)\n",
        "  print(\"up vector was\", up)\n",
        "  R = rotmat(up,[0,0,1]) # rotate up vector to [0,0,1]\n",
        "  R = np.pad(R,[0,1])\n",
        "  R[-1, -1] = 1\n",
        "\n",
        "  for f in out[\"frames\"]:\n",
        "    f[\"transform_matrix\"] = np.matmul(R, f[\"transform_matrix\"]) # rotate up to be the z axis\n",
        "  \n",
        "  # find a central point they are all looking at\n",
        "  print(\"computing center of attention...\")\n",
        "  totw = 0.0\n",
        "  totp = np.array([0.0, 0.0, 0.0])\n",
        "  for f in out[\"frames\"]:\n",
        "    mf = f[\"transform_matrix\"][0:3,:]\n",
        "    for g in out[\"frames\"]:\n",
        "      mg = g[\"transform_matrix\"][0:3,:]\n",
        "      p, w = closest_point_2_lines(mf[:,3], mf[:,2], mg[:,3], mg[:,2])\n",
        "      if w > 0.01:\n",
        "        totp += p*w\n",
        "        totw += w\n",
        "  totp /= totw\n",
        "  print(totp) # the cameras are looking at totp\n",
        "  for f in out[\"frames\"]:\n",
        "    f[\"transform_matrix\"][0:3,3] -= totp\n",
        "\n",
        "  avglen = 0.\n",
        "  for f in out[\"frames\"]:\n",
        "    avglen += np.linalg.norm(f[\"transform_matrix\"][0:3,3])\n",
        "  avglen /= nframes\n",
        "  print(\"avg camera distance from origin\", avglen)\n",
        "  for f in out[\"frames\"]:\n",
        "    f[\"transform_matrix\"][0:3,3] *= 4.0 / avglen # scale to \"nerf sized\"\n",
        "\n",
        "for f in out[\"frames\"]:\n",
        "  f[\"transform_matrix\"] = f[\"transform_matrix\"].tolist()\n",
        "print(nframes,\"frames\")\n",
        "print(f\"writing {OUT_PATH}\")\n",
        "with open(OUT_PATH, \"w\") as outfile:\n",
        "  json.dump(out, outfile, indent=2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y_oMNHP3E4QR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}